{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "This script prepares data related to food justice locations, including forward geocoding of addresses, for use with ArcGIS Pro. \n",
    "- Loads the file provided by the Client (Rainier Beach Action Coalition) that contains infomation about food locations\n",
    "- Performs data cleaning and ETL steps to simplify forward geocoding and mapping\n",
    "- Calls LocationIq API to obtain lat/long \n",
    "- Transforms output into AcrGIS Pro friendly format and writes out to Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define reference objects \n",
    "- Source data path and ETL items\n",
    "- Common LocationIq API parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path and dtypes for client supplied data\n",
    "# This file contains the FJ categories assigned by the client\n",
    "\n",
    "rBeachFJ_path = r'C:\\\\Users\\\\' # Path to source data\n",
    "\n",
    "\n",
    "rBeachFJ_dtypes = {'id':'object', 'zip':'object', 'Food Swamp':'object', 'Food Desert': 'object',\n",
    "                   'Biopic Owned':'object', 'Free Food':'object', 'Farms':'object',\n",
    "                   'Land Ownership':'object', 'Commercial Kitchens':'object'}\n",
    "\n",
    "\n",
    "# List of map category column names \n",
    "mapCatCols = ['Food_Swamp', 'Food_Desert','BIPOC_Owned', 'Free_Food', 'Farms', 'Land_Ownership','Commercial_Kitchens']\n",
    "\n",
    "\n",
    "# List of updated column names\n",
    "rBeachFJ_newCols = ['LocID', 'FoodBusiness_YN', 'Business_Name', 'Business_Address', 'State', 'Zip', 'Website', 'Category', 'Food_Swamp', 'Food_Desert',\n",
    "               'BIPOC_Owned', 'Free_Food', 'Farms', 'Land_Ownership','Commercial_Kitchens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View box, provide limits of returned locations\n",
    "maxLat = '47.59209'\n",
    "minLat = '47.48523'\n",
    "maxLong = '-122.217'\n",
    "minLong = '-122.34053'\n",
    "\n",
    "# Create viewbox string, to simplify call to LocationIq API\n",
    "viewboxString = maxLong + ',' +  maxLat + ',' +  minLong + ',' +  minLat\n",
    "\n",
    "# Prepare dict with non-address parameters, for use with LocationIq API\n",
    "locIqParams = {'key': 'pk.c9ffece8c3c21a0c517497d54fd77a44',\n",
    "               'format' : 'json',\n",
    "               'limit' : '1',\n",
    "               'viewbox' : viewboxString,\n",
    "               'bounded':'1'\n",
    "              }\n",
    "\n",
    "\n",
    "# Define dictionary to simplify picking columns for use with LocIQ API\n",
    "# keys = LocIQ API parameters, values = column names \n",
    "\n",
    "splitAddy_keyMap = {'street' : 'StreetAddress',\n",
    "                    'city' : 'City',\n",
    "                    'state' : 'State',\n",
    "                    'postalcode' : 'Zip'\n",
    "                       }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define functions\n",
    "Several fucntions are used to simplify tasks. \n",
    "- Clean addresses\n",
    "- Find street address, to standarize address format \n",
    "- Split addresses into API compliant dictionary \n",
    "- Get lat/long, using LocationIq API\n",
    "- Remove NaN rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean addresses of pre-identified errors, except when error, return origional address\n",
    "\n",
    "def clean_address(addy):\n",
    "    \n",
    "    addyErr = False\n",
    "    \n",
    "    cleanAddy = addy\n",
    "    \n",
    "    # Clean addresses, except when error, return origional address\n",
    "    \n",
    "    try: \n",
    "        cleanAddy = cleanAddy.replace('MLK', 'Martin Luther King')\n",
    "        cleanAddy = cleanAddy.replace('Mlk', 'Martin Luther King Jr Way S')\n",
    "        cleanAddy = cleanAddy.replace('\\n', ', ')\n",
    "        cleanAddy = cleanAddy.replace('SSeattle', 'S, Seattle')\n",
    "        cleanAddy = cleanAddy.replace('StSeattle', 'St, Seattle')\n",
    "        cleanAddy = cleanAddy.replace('Rainer', 'Rainier')\n",
    "        \n",
    "    except:\n",
    "        addyErr = True   # Identify error producing address\n",
    "        \n",
    "        return addyErr, addy\n",
    "    \n",
    "    return addyErr, cleanAddy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split prepopulated address field to obtain only the street address field, i.e. \"Address1\"\n",
    "\n",
    "def get_StreetAddress(addy_str):\n",
    "    \n",
    "    try:\n",
    "    \n",
    "      streetAddy = addy_str.split(',')[0]\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        streetAddy = '' # Return a blank street address, if error\n",
    "    \n",
    "    return streetAddy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map business address to LocationIQ parameters\n",
    "# Returns dict for use in LocationIQ API\n",
    "\n",
    "def get_SplitAddy (splitAddy_keyMap, addyRow):\n",
    "    \n",
    "    splitAddy_keys = list(splitAddy_keyMap.keys())\n",
    "    splitAddy_idx = list(splitAddy_keyMap.values())\n",
    "    splitAddy_vals = []\n",
    "    \n",
    "    for idxval in splitAddy_idx:\n",
    "        splitAddy_vals.append(addyRow[idxval])\n",
    "        \n",
    "    splitAddy_dict = dict(zip(splitAddy_keys, splitAddy_vals))\n",
    "    \n",
    "    return splitAddy_dict\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calls LocationIq API with mapped address parameters\n",
    "# Reads returned JSON file to find lat/long\n",
    "# Returns: lat, long, response object, and error dict\n",
    "\n",
    "def get_LatLong (params_dict, count):\n",
    "    \n",
    "    error_dict = {}\n",
    "    \n",
    "    locIqURL = 'https://us1.locationiq.com/v1/search.php'\n",
    "    \n",
    "    #LocIqToken ='myToken'\n",
    "    \n",
    "    #params = {'key': LocIqToken, 'q': addy_string, 'format':'json'}\n",
    "    \n",
    "    resp = requests.get(locIqURL, params_dict)\n",
    "    \n",
    "    try: \n",
    "        locIqResponse = resp.json()\n",
    "    \n",
    "        r_lat = float(resp.json()[0]['lat'])\n",
    "\n",
    "        r_long = float(resp.json()[0]['lon'])\n",
    "        \n",
    "    except Exception as e:\n",
    "        \n",
    "        r_lat = None\n",
    "        r_long = None\n",
    "        \n",
    "        error_dict = {str(count):e}\n",
    "    \n",
    "    return r_lat, r_long, locIqResponse, error_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove rows with Nan values in any row of a passes list of col names\n",
    "# Intended for use with removing rows missing lat/long\n",
    "\n",
    "def removeNanRows(df, checkCol_ls):\n",
    "    \n",
    "    for col in checkCol_ls:\n",
    "        \n",
    "        df.dropna(axis = 0, subset = [col], inplace = True)\n",
    "        \n",
    "    df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    \n",
    "    return df          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Begin main section \n",
    "The main section of the program follows these steps. \n",
    "- Load and transform source data \n",
    "- Clean and transform addresses \n",
    "- Get lat/long, using LocationIq API\n",
    "- Remove rows with missing data\n",
    "- Write out to Excel, for use with ArcGIS Pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file of FJ locations. This client supplied file contains a multi-level index.\n",
    "# Decision to select a single-level index to simplify dtype assignment \n",
    "\n",
    "# Option 1: For selecting the mulit-level column index \n",
    "\n",
    "#rBeachFJ_df = pd.read_excel(rBeachFJ_path, sheet_name = 'Rainier Beach Food', header = [0,1],  dtype = rBeachFJ_dtypes)\n",
    "\n",
    "\n",
    "# Option 2: For selecting only row 0 as column index; simplifies dtype assignment \n",
    "# Skips row 1 to avoid creating a multi-level index\n",
    "\n",
    "rBeachFJ_df = pd.read_excel(rBeachFJ_path, sheet_name = 'Rainier Beach Food', header = [0],  dtype = rBeachFJ_dtypes,\n",
    "                            skiprows = lambda x: x in [1])\n",
    "\n",
    "# Drop unneeded column\n",
    "rBeachFJ_df.drop(columns = ['Commercial kitchen available to businesses? '], inplace = True)\n",
    "\n",
    "# Assign new column names\n",
    "rBeachFJ_df.columns = rBeachFJ_newCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill map categories with Yes or No values; replace NaN and 'x'\n",
    "\n",
    "for col in mapCatCols:\n",
    "    \n",
    "    for i in range(len(rBeachFJ_df)):\n",
    "        \n",
    "        if rBeachFJ_df.loc[i, col] == 'x':\n",
    "            \n",
    "            rBeachFJ_df.loc[i, col] = 'Yes'\n",
    "            \n",
    "        else:\n",
    "        \n",
    "             rBeachFJ_df.loc[i, col] = 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign new col index orders\n",
    "\n",
    "rBeachGis_newIndex = ['LocID', 'FoodBusiness_YN', 'Business_Name', 'Business_Address', 'State','Zip','Latitude', 'Longitude',\n",
    "                       'Website', 'Category', 'Food_Swamp', 'Food_Desert','BIPOC_Owned', 'Free_Food', 'Farms', 'Land_Ownership','Commercial_Kitchens', ]\n",
    "\n",
    "rBeachFJ_df = rBeachFJ_df.reindex(rBeachGis_newIndex, axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through df to clean addresses and split street address \n",
    "\n",
    "#rBeachFJ_df['Business_Address'] = rBeachFJ_df.Business_Address.apply(lambda x : str(x).replace('\\n', ', '))\n",
    "\n",
    "badAddyIdx_ls =[]\n",
    "\n",
    "for i in range(len(rBeachFJ_df)):\n",
    "    \n",
    "    cleanAddyErr, rBeachFJ_df.loc[i, 'Business_Address']  = clean_address( rBeachFJ_df.loc[i, 'Business_Address'])\\\n",
    "    \n",
    "    if cleanAddyErr:\n",
    "        badAddyIdx_ls.append(i) # Capture index values of addresses that produce errors\n",
    "        \n",
    "    rBeachFJ_df.loc[i,'StreetAddress'] = get_StreetAddress(rBeachFJ_df.loc[i, 'Business_Address'])\n",
    "\n",
    "# Assign Seattle as the city name for all locations. \n",
    "\n",
    "rBeachFJ_df['City'] = 'Seattle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time:  499.1313512325287\n"
     ]
    }
   ],
   "source": [
    "# Use function to get lat/long from LocationIQ\n",
    "\n",
    "startTime = time.time() # Start timer, to learn how long geocoding takes to complete \n",
    "\n",
    "# Create empty lists for capturing API request and return information \n",
    "addyParams_ls = [] # For API request dicts\n",
    "addyResponse_ls = [] # For API response \n",
    "addyError_ls = [] #For debug\n",
    "\n",
    "for i in range(len(rBeachFJ_df)):\n",
    "    \n",
    "    #Select row from df and get split addy\n",
    "    nextRow = rBeachFJ_df.iloc[i]    \n",
    "    nextAddy_dict = get_SplitAddy(splitAddy_keyMap, nextRow)\n",
    "\n",
    "    # Combine address with standard API request info, store in list for future reference\n",
    "    nextAddyParams = {**locIqParams, **nextAddy_dict}\n",
    "    addyParams_ls.append(nextAddyParams)\n",
    "    \n",
    "    # Call LocationIq API via function \n",
    "    tempLat, tempLong, addyResponse, addyError = get_LatLong(nextAddyParams, i)\n",
    "\n",
    "    # Append lat/long info to the FJ location \n",
    "    rBeachFJ_df.loc[i, 'Latitude'] = tempLat\n",
    "    rBeachFJ_df.loc[i, 'Longitude'] = tempLong\n",
    "    \n",
    "    # Store API response and any error \n",
    "    addyResponse_ls.append(addyResponse)\n",
    "    addyError_ls.append(addyError)\n",
    "    \n",
    "    # Pause for loop to avoid API throttling \n",
    "    time.sleep(1.1)\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "\n",
    "# Calcuate elapsed time\n",
    "elapsedTime = endTime - startTime\n",
    "print('Elapsed time: ', elapsedTime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any locations missing lat/long (can't be mapped) and reset index. \n",
    "\n",
    "allFjLoc_df = removeNanRows(rBeachFJ_df, ['Latitude', 'Longitude'])\n",
    "allFjLoc_df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split out the desired categories, because ArcPro GIS \"view filters\" don't work on the web map  \n",
    "\n",
    "bipoc_df = allFjLoc_df[allFjLoc_df.BIPOC_Owned == 'Yes']\n",
    "foodSwamp_df = allFjLoc_df[allFjLoc_df.Food_Swamp == 'Yes']\n",
    "foodDesert_df = allFjLoc_df[allFjLoc_df.Food_Desert == 'Yes']\n",
    "freeFood_df = allFjLoc_df[allFjLoc_df.Free_Food == 'Yes']\n",
    "farms_df = allFjLoc_df[allFjLoc_df.Farms == 'Yes']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out FJ locations, by categories, for use by ArcPro GIS \n",
    "\n",
    "with pd.ExcelWriter(r'C:\\\\Users',# path to output file \n",
    "                    date_format='%Y-%m-%d-%H-%M-%S', datetime_format='YYYY-MM-DD-HH:MM:SS') as mapData_writer:\n",
    "    \n",
    "    rBeachFJ_df.to_excel(mapData_writer, sheet_name = 'All FJ Locations', index = False)\n",
    "    allFjLoc_df.to_excel(mapData_writer, sheet_name = 'API Found Locations', index = False)\n",
    "    bipoc_df.to_excel(mapData_writer, sheet_name = 'BIPOC Owned Locations', index = False)\n",
    "    foodSwamp_df.to_excel(mapData_writer, sheet_name = 'Food Swamp Locations', index = False)\n",
    "    foodDesert_df.to_excel(mapData_writer, sheet_name = 'Food Desert Locations', index = False)\n",
    "    freeFood_df.to_excel(mapData_writer, sheet_name = 'Free Food Locations', index = False)\n",
    "    farms_df.to_excel(mapData_writer, sheet_name = 'Farm Locations', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f18310f7eb04fcdecd41dd2753e42e607afadcee65e6289b049db038aececc7b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
